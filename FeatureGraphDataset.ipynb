{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from torch import LongTensor, Tensor\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGraphDataset(object):\n",
    "\n",
    "    def __init__(self, features, label, adj):\n",
    "        '''Initalization\n",
    "        \n",
    "        Manually initalize a feature and graph dataset.\n",
    "\n",
    "        Args:\n",
    "            features: numpy ndarray, [[f1, f2, ...], [f1, f2, ...]]\n",
    "            label: numpy ndarray, [0, 1, 2, 0, ...], label[i] == -1 if its class is unknow\n",
    "            adj: dict of (int, list of int), {[1,2],[0,3],...}\n",
    "        '''\n",
    "        assert len(features) == len(label)\n",
    "        assert type(features) == type(label) == np.ndarray\n",
    "        self.features, self.label = features, label\n",
    "        self.n = len(features) # num of instances\n",
    "        self.m = np.max(label) + 1 # num of classes\n",
    "        self.k = features.shape[1] # num of features\n",
    "        self.adj = adj\n",
    "        ratio = 0.5\n",
    "        for k, v in adj.items():\n",
    "            s = len(v)\n",
    "            adj_features = reduce(lambda x,y: x + y, [self.features[y] for y in v])\n",
    "            self.features[k] = self.features[k] * ratio + adj_features * (1 - ratio) / s\n",
    "\n",
    "    def setting(self, label_num_per_class, test_num):\n",
    "        '''Set label data and test set in semi-supervised learning\n",
    "\n",
    "        Label data and test set should be settled at first. \n",
    "\n",
    "        '''\n",
    "        self.test_ids = random.sample(range(self.n), test_num)\n",
    "        remains = set(range(self.n)) - set(self.test_ids)\n",
    "        num_of_class = [0] * self.m\n",
    "        self.label_ids = []\n",
    "        for i in remains:\n",
    "            if num_of_class[self.label[i]] < label_num_per_class:\n",
    "                self.label_ids.append(i)\n",
    "            num_of_class[self.label[i]] += 1\n",
    "        self.unlabel_ids = list(set(range(self.n)) - set(self.label_ids))\n",
    "        self.test_num, self.label_num = test_num, sum(num_of_class)\n",
    "\n",
    "\n",
    "    def label_batch(self, batch_size, tensor = True):\n",
    "        '''Return a batch of label data features\n",
    "\n",
    "        Random sample from label data\n",
    "\n",
    "        Return:\n",
    "            tuple: ([id0, id1, ...], [[f1, f2, ...], ...(batch_size)](type: numpy.ndarray), [0,1,2,...(batch_size)](type: numpy.ndarray))\n",
    "        '''\n",
    "        assert(len(self.label_ids) >= batch_size)\n",
    "        ids = random.sample(self.label_ids, batch_size)\n",
    "        return (LongTensor(ids), Tensor(self.features[ids]), LongTensor(self.label[ids])) if tensor else (ids, self.features[ids], self.label[ids])\n",
    "    \n",
    "    def unlabel_batch(self, batch_size, tensor = True):\n",
    "        '''Return a batch of unlabel data features\n",
    "        \n",
    "        Random sample from label data\n",
    "\n",
    "        Return:\n",
    "            tuple: ([id0, ...], [[f1, f2, ...], ...(batch_size)](type: numpy.ndarray))\n",
    "        '''\n",
    "        if batch_size == -1:\n",
    "            ids = self.unlabel_ids\n",
    "        else:\n",
    "            ids = random.sample(self.unlabel_ids, batch_size)\n",
    "        return (LongTensor(ids), Tensor(self.features[ids])) if tensor else (ids, self.features[ids])\n",
    "\n",
    "    def test_batch(self, batch_size = -1, tensor = True):\n",
    "        if batch_size == -1:\n",
    "            ids = self.test_ids\n",
    "        else:\n",
    "            ids = random.sample(self.test_ids, batch_size)\n",
    "        return (LongTensor(ids), Tensor(self.features[ids]), LongTensor(self.label[ids])) if tensor else (ids, self.features[ids], self.label[ids])\n",
    "\n",
    "    def adj_batch(self, batch, tensor = True):\n",
    "        ids = [random.choice(self.adj[i]) for i in batch]\n",
    "        return (LongTensor(ids), Tensor(self.features[ids])) if tensor else (ids, self.features[ids])\n",
    "\n",
    "    def read_embbedings(self, embbeding_file):\n",
    "        '''read graph embbedings from file\n",
    "\n",
    "        Read graph embbedings generated by OpenNE system.        \n",
    "        '''\n",
    "        with open(embbeding_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            n, self.d = [int(i) for i in lines[0].split()]\n",
    "            assert n == self.n\n",
    "            self.embbedings = np.zeros((n, self.d))\n",
    "            for line in lines[1:]:\n",
    "                line = line.split()\n",
    "                self.embbedings[int(line[0])] = [float(i) for i in line[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
